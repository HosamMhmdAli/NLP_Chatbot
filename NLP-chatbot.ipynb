{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:54:45.966173Z","iopub.execute_input":"2023-07-23T19:54:45.966913Z","iopub.status.idle":"2023-07-23T19:54:45.971907Z","shell.execute_reply.started":"2023-07-23T19:54:45.966874Z","shell.execute_reply":"2023-07-23T19:54:45.971052Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_df= pd.read_csv('/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv', index_col=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:54:47.155518Z","iopub.execute_input":"2023-07-23T19:54:47.156229Z","iopub.status.idle":"2023-07-23T19:54:48.740164Z","shell.execute_reply.started":"2023-07-23T19:54:47.156180Z","shell.execute_reply":"2023-07-23T19:54:48.738952Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:54:57.041884Z","iopub.execute_input":"2023-07-23T19:54:57.042282Z","iopub.status.idle":"2023-07-23T19:54:57.074448Z","shell.execute_reply.started":"2023-07-23T19:54:57.042249Z","shell.execute_reply":"2023-07-23T19:54:57.073298Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0                                           question  \\\n0                1  Well, I thought we'd start with pronunciation,...   \n1                2  Not the hacking and gagging and spitting part....   \n2                3  You're asking me out.  That's so cute. What's ...   \n3                4  No, no, it's my fault -- we didn't have a prop...   \n4                9     Gosh, if only we could find Kat a boyfriend...   \n...            ...                                                ...   \n139404      221608    Well that one. The one who keeps looking at me.   \n139405      221609  Choose your targets men. That's right Watch th...   \n139406      221610  Colonel Durnford... William Vereker. I hear yo...   \n139407      221611                           Your orders, Mr Vereker?   \n139408      221612  I'm to take the Sikali with the main column to...   \n\n                                                   answer  \\\n0       Not the hacking and gagging and spitting part....   \n1       Okay... then how 'bout we try out some French ...   \n2                                              Forget it.   \n3                                                Cameron.   \n4                               Let me see what I can do.   \n...                                                   ...   \n139404  ft could be you flatter yourself CoghilL It's ...   \n139405  Keep steady. You're the best shots of the Twen...   \n139406  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n139407  I'm to take the Sikali with the main column to...   \n139408  Lord Chelmsford seems to want me to stay back ...   \n\n                                          question_as_int  \\\n0       [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n1       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n2       [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n3       [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n4       [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n...                                                   ...   \n139404  [54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...   \n139405  [34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...   \n139406  [34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...   \n139407  [56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...   \n139408  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...   \n\n                                            answer_as_int  question_len  \\\n0       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71   \n1       [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55   \n2                 [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62   \n3                        [34, 63, 75, 67, 80, 77, 76, 14]            65   \n4       [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46   \n...                                                   ...           ...   \n139404  [68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...            47   \n139405  [42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...            61   \n139406  [38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...            74   \n139407  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...            24   \n139408  [43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...            56   \n\n        answer_len  \n0               55  \n1               73  \n2               10  \n3                8  \n4               25  \n...            ...  \n139404          59  \n139405          85  \n139406          60  \n139407          56  \n139408          62  \n\n[139409 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_as_int</th>\n      <th>answer_as_int</th>\n      <th>question_len</th>\n      <th>answer_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>71</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n      <td>55</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n      <td>62</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n      <td>65</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n      <td>46</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>221608</td>\n      <td>Well that one. The one who keeps looking at me.</td>\n      <td>ft could be you flatter yourself CoghilL It's ...</td>\n      <td>[54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...</td>\n      <td>[68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...</td>\n      <td>47</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>221609</td>\n      <td>Choose your targets men. That's right Watch th...</td>\n      <td>Keep steady. You're the best shots of the Twen...</td>\n      <td>[34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...</td>\n      <td>[42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...</td>\n      <td>61</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>221610</td>\n      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n      <td>[34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...</td>\n      <td>[38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...</td>\n      <td>74</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>221611</td>\n      <td>Your orders, Mr Vereker?</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>[56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...</td>\n      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n      <td>24</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>221612</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>Lord Chelmsford seems to want me to stay back ...</td>\n      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n      <td>[43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...</td>\n      <td>56</td>\n      <td>62</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df.drop(['Unnamed: 0','question_as_int','answer_as_int','question_len','answer_len'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:00.377040Z","iopub.execute_input":"2023-07-23T19:55:00.377449Z","iopub.status.idle":"2023-07-23T19:55:00.407498Z","shell.execute_reply.started":"2023-07-23T19:55:00.377419Z","shell.execute_reply":"2023-07-23T19:55:00.406219Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:01.402195Z","iopub.execute_input":"2023-07-23T19:55:01.402985Z","iopub.status.idle":"2023-07-23T19:55:01.466875Z","shell.execute_reply.started":"2023-07-23T19:55:01.402942Z","shell.execute_reply":"2023-07-23T19:55:01.465772Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 139409 entries, 0 to 139408\nData columns (total 2 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   question  139409 non-null  object\n 1   answer    139409 non-null  object\ndtypes: object(2)\nmemory usage: 2.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:02.340766Z","iopub.execute_input":"2023-07-23T19:55:02.341138Z","iopub.status.idle":"2023-07-23T19:55:02.355356Z","shell.execute_reply.started":"2023-07-23T19:55:02.341109Z","shell.execute_reply":"2023-07-23T19:55:02.354096Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                 question  \\\n0       Well, I thought we'd start with pronunciation,...   \n1       Not the hacking and gagging and spitting part....   \n2       You're asking me out.  That's so cute. What's ...   \n3       No, no, it's my fault -- we didn't have a prop...   \n4          Gosh, if only we could find Kat a boyfriend...   \n...                                                   ...   \n139404    Well that one. The one who keeps looking at me.   \n139405  Choose your targets men. That's right Watch th...   \n139406  Colonel Durnford... William Vereker. I hear yo...   \n139407                           Your orders, Mr Vereker?   \n139408  I'm to take the Sikali with the main column to...   \n\n                                                   answer  \n0       Not the hacking and gagging and spitting part....  \n1       Okay... then how 'bout we try out some French ...  \n2                                              Forget it.  \n3                                                Cameron.  \n4                               Let me see what I can do.  \n...                                                   ...  \n139404  ft could be you flatter yourself CoghilL It's ...  \n139405  Keep steady. You're the best shots of the Twen...  \n139406  Good ones, yes, Mr Vereker. Gentlemen who can ...  \n139407  I'm to take the Sikali with the main column to...  \n139408  Lord Chelmsford seems to want me to stay back ...  \n\n[139409 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>Well that one. The one who keeps looking at me.</td>\n      <td>ft could be you flatter yourself CoghilL It's ...</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>Choose your targets men. That's right Watch th...</td>\n      <td>Keep steady. You're the best shots of the Twen...</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>Your orders, Mr Vereker?</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>Lord Chelmsford seems to want me to stay back ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T20:08:59.052231Z","iopub.execute_input":"2023-07-23T20:08:59.052639Z","iopub.status.idle":"2023-07-23T20:08:59.063359Z","shell.execute_reply.started":"2023-07-23T20:08:59.052606Z","shell.execute_reply":"2023-07-23T20:08:59.062577Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7d7dfe631bd0>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_6383e\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_6383e_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n      <th id=\"T_6383e_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_6383e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_6383e_row0_col0\" class=\"data row0 col0\" ><start> well  i thought we d start with pronunciation  if that s okay with you  <end></td>\n      <td id=\"T_6383e_row0_col1\" class=\"data row0 col1\" ><start> not the hacking and gagging and spitting part   please  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_6383e_row1_col0\" class=\"data row1 col0\" ><start> not the hacking and gagging and spitting part   please  <end></td>\n      <td id=\"T_6383e_row1_col1\" class=\"data row1 col1\" ><start> okay    then how  bout we try out some french cuisine   saturday   night  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_6383e_row2_col0\" class=\"data row2 col0\" ><start> you re asking me out   that s so cute  what s your name again  <end></td>\n      <td id=\"T_6383e_row2_col1\" class=\"data row2 col1\" ><start> forget it  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_6383e_row3_col0\" class=\"data row3 col0\" ><start> no  no  it s my fault    we didn t have a proper introduction     <end></td>\n      <td id=\"T_6383e_row3_col1\" class=\"data row3 col1\" ><start> cameron  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_6383e_row4_col0\" class=\"data row4 col0\" ><start> gosh  if only we could find kat a boyfriend    <end></td>\n      <td id=\"T_6383e_row4_col1\" class=\"data row4 col1\" ><start> let me see what i can do  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_6383e_row5_col0\" class=\"data row5 col0\" ><start> c esc ma tete  this is my head <end></td>\n      <td id=\"T_6383e_row5_col1\" class=\"data row5 col1\" ><start> right   see   you re ready for the quiz  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_6383e_row6_col0\" class=\"data row6 col0\" ><start> that s because it s such a nice one  <end></td>\n      <td id=\"T_6383e_row6_col1\" class=\"data row6 col1\" ><start> forget french  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_6383e_row7_col0\" class=\"data row7 col0\" ><start> how is our little find the wench a date plan progressing  <end></td>\n      <td id=\"T_6383e_row7_col1\" class=\"data row7 col1\" ><start> well  there s someone i think might be    <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_6383e_row8_col0\" class=\"data row8 col0\" ><start> you have my word   as a gentleman <end></td>\n      <td id=\"T_6383e_row8_col1\" class=\"data row8 col1\" ><start> you re sweet  <end></td>\n    </tr>\n    <tr>\n      <th id=\"T_6383e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_6383e_row9_col0\" class=\"data row9 col0\" ><start> sure have  <end></td>\n      <td id=\"T_6383e_row9_col1\" class=\"data row9 col1\" ><start> i really  really  really wanna go  but i can t   not unless my sister goes  <end></td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"code","source":"data_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T20:09:45.858210Z","iopub.execute_input":"2023-07-23T20:09:45.858636Z","iopub.status.idle":"2023-07-23T20:09:45.874728Z","shell.execute_reply.started":"2023-07-23T20:09:45.858599Z","shell.execute_reply":"2023-07-23T20:09:45.873748Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                                 question  \\\n124111                           <start> i have to  <end>   \n128593         <start> five to three  you re early  <end>   \n24839             <start> and what was your answer  <end>   \n121021                   <start> nice work  norman  <end>   \n103967  <start> matthew lives on the upper west side  ...   \n61016             <start> she told you  didn t she  <end>   \n29989                              <start> jesus    <end>   \n127886               <start> you missed on purpose  <end>   \n14154            <start> i ll be okay  holy shit    <end>   \n47967   <start> get undressed in your own room  would ...   \n\n                                                   answer  \n124111          <start> when can i see  you again   <end>  \n128593  <start> should i come back in five minutes  <end>  \n24839   <start> i said i wanted to talk to a lawyer  <...  \n121021           <start> whatever i can do to help  <end>  \n103967     <start> any priors   any police record   <end>  \n61016           <start> what did she tell me  beth  <end>  \n29989                  <start> get back in the car  <end>  \n127886     <start> i didn t  i told you  i can t    <end>  \n14154        <start> don t get up  take a second    <end>  \n47967     <start> i thought you d missed the train  <end>  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>124111</th>\n      <td>&lt;start&gt; i have to  &lt;end&gt;</td>\n      <td>&lt;start&gt; when can i see  you again   &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>128593</th>\n      <td>&lt;start&gt; five to three  you re early  &lt;end&gt;</td>\n      <td>&lt;start&gt; should i come back in five minutes  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>24839</th>\n      <td>&lt;start&gt; and what was your answer  &lt;end&gt;</td>\n      <td>&lt;start&gt; i said i wanted to talk to a lawyer  &lt;...</td>\n    </tr>\n    <tr>\n      <th>121021</th>\n      <td>&lt;start&gt; nice work  norman  &lt;end&gt;</td>\n      <td>&lt;start&gt; whatever i can do to help  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>103967</th>\n      <td>&lt;start&gt; matthew lives on the upper west side  ...</td>\n      <td>&lt;start&gt; any priors   any police record   &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>61016</th>\n      <td>&lt;start&gt; she told you  didn t she  &lt;end&gt;</td>\n      <td>&lt;start&gt; what did she tell me  beth  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>29989</th>\n      <td>&lt;start&gt; jesus    &lt;end&gt;</td>\n      <td>&lt;start&gt; get back in the car  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>127886</th>\n      <td>&lt;start&gt; you missed on purpose  &lt;end&gt;</td>\n      <td>&lt;start&gt; i didn t  i told you  i can t    &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>14154</th>\n      <td>&lt;start&gt; i ll be okay  holy shit    &lt;end&gt;</td>\n      <td>&lt;start&gt; don t get up  take a second    &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>47967</th>\n      <td>&lt;start&gt; get undressed in your own room  would ...</td>\n      <td>&lt;start&gt; i thought you d missed the train  &lt;end&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def clean_text(text):\n  text = text.lower()\n  text = re.sub('\\[.*?\\]', '', text)\n  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n  text = re.sub('<.*?>+', '', text)\n  text = re.sub('\\n', '', text)\n  text = re.sub(r'[^\\w]',' ',text)\n  text = re.sub('\\w*\\d\\w*', '', text)\n  return text\n\ndata_df.question = data_df.question.map(clean_text)\ndata_df.answer = data_df.answer.map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:03.266133Z","iopub.execute_input":"2023-07-23T19:55:03.266508Z","iopub.status.idle":"2023-07-23T19:55:07.271907Z","shell.execute_reply.started":"2023-07-23T19:55:03.266480Z","shell.execute_reply":"2023-07-23T19:55:07.270784Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def add_start_end(text):\n  text = f'<start> {text} <end>'\n  return text\n\ndata_df.question = data_df.question.map(add_start_end)\ndata_df.answer = data_df.answer.map(add_start_end)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:10.001558Z","iopub.execute_input":"2023-07-23T19:55:10.002904Z","iopub.status.idle":"2023-07-23T19:55:10.107613Z","shell.execute_reply.started":"2023-07-23T19:55:10.002861Z","shell.execute_reply":"2023-07-23T19:55:10.106673Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:10.899208Z","iopub.execute_input":"2023-07-23T19:55:10.900112Z","iopub.status.idle":"2023-07-23T19:55:10.913091Z","shell.execute_reply.started":"2023-07-23T19:55:10.900069Z","shell.execute_reply":"2023-07-23T19:55:10.911725Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                 question  \\\n0       <start> well  i thought we d start with pronun...   \n1       <start> not the hacking and gagging and spitti...   \n2       <start> you re asking me out   that s so cute ...   \n3       <start> no  no  it s my fault    we didn t hav...   \n4       <start> gosh  if only we could find kat a boyf...   \n...                                                   ...   \n139404  <start> well that one  the one who keeps looki...   \n139405  <start> choose your targets men  that s right ...   \n139406  <start> colonel durnford    william vereker  i...   \n139407             <start> your orders  mr vereker  <end>   \n139408  <start> i m to take the sikali with the main c...   \n\n                                                   answer  \n0       <start> not the hacking and gagging and spitti...  \n1       <start> okay    then how  bout we try out some...  \n2                                <start> forget it  <end>  \n3                                  <start> cameron  <end>  \n4                 <start> let me see what i can do  <end>  \n...                                                   ...  \n139404  <start> ft could be you flatter yourself coghi...  \n139405  <start> keep steady  you re the best shots of ...  \n139406  <start> good ones  yes  mr vereker  gentlemen ...  \n139407  <start> i m to take the sikali with the main c...  \n139408  <start> lord chelmsford seems to want me to st...  \n\n[139409 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;start&gt; well  i thought we d start with pronun...</td>\n      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n      <td>&lt;start&gt; okay    then how  bout we try out some...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;start&gt; you re asking me out   that s so cute ...</td>\n      <td>&lt;start&gt; forget it  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;start&gt; no  no  it s my fault    we didn t hav...</td>\n      <td>&lt;start&gt; cameron  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;start&gt; gosh  if only we could find kat a boyf...</td>\n      <td>&lt;start&gt; let me see what i can do  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>&lt;start&gt; well that one  the one who keeps looki...</td>\n      <td>&lt;start&gt; ft could be you flatter yourself coghi...</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>&lt;start&gt; choose your targets men  that s right ...</td>\n      <td>&lt;start&gt; keep steady  you re the best shots of ...</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>&lt;start&gt; colonel durnford    william vereker  i...</td>\n      <td>&lt;start&gt; good ones  yes  mr vereker  gentlemen ...</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>&lt;start&gt; your orders  mr vereker  &lt;end&gt;</td>\n      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n      <td>&lt;start&gt; lord chelmsford seems to want me to st...</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(lang):\n  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n      filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<OOV>'\n  )\n  lang_tokenizer.fit_on_texts(lang)\n  tensor = lang_tokenizer.texts_to_sequences(lang)\n  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n  return tensor, lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:11.928644Z","iopub.execute_input":"2023-07-23T19:55:11.929050Z","iopub.status.idle":"2023-07-23T19:55:11.934591Z","shell.execute_reply.started":"2023-07-23T19:55:11.929018Z","shell.execute_reply":"2023-07-23T19:55:11.933548Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"question_sequence, question_tokenizer = tokenize(data_df.question)\nanswer_sequence, answer_tokenizer = tokenize(data_df.answer)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:13.228475Z","iopub.execute_input":"2023-07-23T19:55:13.228893Z","iopub.status.idle":"2023-07-23T19:55:22.711869Z","shell.execute_reply.started":"2023-07-23T19:55:13.228858Z","shell.execute_reply":"2023-07-23T19:55:22.710647Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = model_selection.train_test_split(question_sequence, \n                answer_sequence, test_size = 0.1, random_state=42) \n\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:33.042841Z","iopub.execute_input":"2023-07-23T19:55:33.043247Z","iopub.status.idle":"2023-07-23T19:55:33.097417Z","shell.execute_reply.started":"2023-07-23T19:55:33.043212Z","shell.execute_reply":"2023-07-23T19:55:33.096355Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((125468, 29), (13941, 29), (125468, 32), (13941, 32))"},"metadata":{}}]},{"cell_type":"code","source":"def convert(lang, tensor):\n  for t in tensor:\n    if t!=0:\n      print('%d---> %s' % (t, lang.index_word[t]))\n\nprint('Question')\nconvert(question_tokenizer, x_train[0])\nprint()\nprint('Answer')\nconvert(answer_tokenizer, y_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:33.973812Z","iopub.execute_input":"2023-07-23T19:55:33.974191Z","iopub.status.idle":"2023-07-23T19:55:33.981330Z","shell.execute_reply.started":"2023-07-23T19:55:33.974161Z","shell.execute_reply":"2023-07-23T19:55:33.980079Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Question\n2---> <start>\n80---> yeah\n13---> that\n8---> s\n11002---> blush\n36---> on\n32---> my\n301---> wife\n3384---> uses\n9---> it\n3---> <end>\n\nAnswer\n2---> <start>\n204---> ask\n5535---> travis\n22---> he\n7---> s\n6---> the\n1765---> ladies\n104---> man\n3---> <end>\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_inp_size = len(question_tokenizer.word_index)+1\nvocab_tar_size =  len(answer_tokenizer.word_index)+1\nembedding_dim = 256\nunits = 1024\nbatch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:34.878675Z","iopub.execute_input":"2023-07-23T19:55:34.879084Z","iopub.status.idle":"2023-07-23T19:55:34.884143Z","shell.execute_reply.started":"2023-07-23T19:55:34.879053Z","shell.execute_reply":"2023-07-23T19:55:34.882706Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_dataset(x, y, batch_size=32):\n  data = tf.data.Dataset.from_tensor_slices((x, y))\n\n  data = data.shuffle(1028)\n  data = data.batch(batch_size, drop_remainder=True)\n\n  data = data.prefetch(tf.data.experimental.AUTOTUNE)\n\n  return data\n\ntrain_dataset = create_dataset(x_train, y_train)\ntest_dataset = create_dataset(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:35.955749Z","iopub.execute_input":"2023-07-23T19:55:35.956135Z","iopub.status.idle":"2023-07-23T19:55:36.108040Z","shell.execute_reply.started":"2023-07-23T19:55:35.956104Z","shell.execute_reply":"2023-07-23T19:55:36.107055Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"  for q, a in train_dataset.take(1):\n    print(f'Question:{q.shape}\\n{q}')\n  \n    print(f'Answer:{a.shape}\\n{a}')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:39.068581Z","iopub.execute_input":"2023-07-23T19:55:39.068989Z","iopub.status.idle":"2023-07-23T19:55:39.187487Z","shell.execute_reply.started":"2023-07-23T19:55:39.068957Z","shell.execute_reply":"2023-07-23T19:55:39.186367Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Question:(32, 29)\n[[    2  1057   474     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    67   133  1084    61    29     4    44     3     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   222     3     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    12    29     4   111    44    45    53     3     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     9    15    99   110   489  1096     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   119  2744     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    29    17   903   275   849     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    13     8    10   232   208   364     4    57    47   127  2223\n    185   134   169  2080    10   122  3268     3     0     0     0     0\n      0     0     0     0     0]\n [    2    62    59   356    20     6   302   467     3     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    18    47   149    83 14586    89     6   882  5197   125    43\n     29  1010     3     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    61   598     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    68    27    50    50    27    68     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     5    23    64    36  2067    69     6   691     8  1164     7\n    152    27 14941     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2 10993   107     6  6415   104   169   826   152    27    68   453\n      3     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    59     7     6   439  1049     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   892  1543     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    48    12     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2 11313  2263   300    18    22   581  7835  2251    18   581   138\n   7487     7  2263  1213     3     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   133  2548   496   101   543   168    24    84    18     5    46\n    195     4   139   889     3     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    80   609     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   115  3426    96    74     4    19    39    10   337   365   158\n     11     4   183   375  6901     3     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    65    29    43   312     4    26    65    43    29     3     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    51     8    57     9     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    15    47   132     4    52     7    78    97   391     3     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    66    49    90    14   793    99    40    13  3125     3     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   668    17    34    11    39     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    72    35    13   184   164     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   148   153     4  5062     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   181   130    94     9     8    39    10   930     3     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    12    29     4   191    40     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    12    40     6   471    16    32  3992   895     3     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2  5061   119   419  2329     6   196     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]]\nAnswer:(32, 32)\n[[  2  13   7 ...   0   0   0]\n [  2  37 240 ...   0   0   0]\n [  2 206   3 ...   0   0   0]\n ...\n [  2 340   5 ...   0   0   0]\n [  2 207   6 ...   0   0   0]\n [  2  26  69 ...   0   0   0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n      super(Encoder, self).__init__()\n\n      self.batch_size = batch_size\n      self.encoder_units = encoder_units\n      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n      self.gru = tf.keras.layers.GRU(self.encoder_units, \n                                           return_sequences=True,\n                                           return_state=True,\n                                           recurrent_initializer = 'glorot_uniform')\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, state = self.gru(x, initial_state = hidden)\n    return output, state\n\n  def initialize_hidden_state(self):\n    return tf.zeros((self.batch_size, self.encoder_units))","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:40.409751Z","iopub.execute_input":"2023-07-23T19:55:40.410136Z","iopub.status.idle":"2023-07-23T19:55:40.417593Z","shell.execute_reply.started":"2023-07-23T19:55:40.410104Z","shell.execute_reply":"2023-07-23T19:55:40.416745Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n      super(Decoder, self).__init__()\n\n      self.batch_size = batch_size\n      self.decoder_units = decoder_units\n      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n      self.gru = tf.keras.layers.GRU(self.decoder_units, \n                                           return_sequences=True,\n                                           return_state=True,\n                                           recurrent_initializer = 'glorot_uniform')\n      \n      self.fc = tf.keras.layers.Dense(vocab_size)\n\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, hidden = self.gru(x, initial_state = hidden)\n    output = tf.reshape(output, (-1, output.shape[2]))\n    x =  tf.nn.softmax(self.fc(output))\n    return x, hidden","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:41.470846Z","iopub.execute_input":"2023-07-23T19:55:41.471592Z","iopub.status.idle":"2023-07-23T19:55:41.479376Z","shell.execute_reply.started":"2023-07-23T19:55:41.471543Z","shell.execute_reply":"2023-07-23T19:55:41.478193Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# vocab_inp_size = len(eng_tokenizer.word_index)+1\n# vocab_tar_size =  len(spn_tokenizer.word_index)+1\n# embedding_dim = 256\n# units = 1024\n# batch_size=32\n\nencoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder(q, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:42.470437Z","iopub.execute_input":"2023-07-23T19:55:42.471465Z","iopub.status.idle":"2023-07-23T19:55:43.066453Z","shell.execute_reply.started":"2023-07-23T19:55:42.471423Z","shell.execute_reply":"2023-07-23T19:55:43.064353Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Encoder output shape: (batch size, sequence length, units) (32, 29, 1024)\nEncoder Hidden state shape: (batch size, units) (32, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n\nsample_decoder_output, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden)\n\nprint ('Decoder output shape: (batch size, vocab_size) {}'.format(sample_decoder_output.shape))","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:44.002872Z","iopub.execute_input":"2023-07-23T19:55:44.003244Z","iopub.status.idle":"2023-07-23T19:55:44.431998Z","shell.execute_reply.started":"2023-07-23T19:55:44.003214Z","shell.execute_reply":"2023-07-23T19:55:44.430836Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Decoder output shape: (batch size, vocab_size) (32, 27849)\n","output_type":"stream"}]},{"cell_type":"code","source":"# create the optimizer using the Adam optimizer\noptimizer = tf.keras.optimizers.Adam()\n# create the loss function\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=False, reduction='none')\n\n# define the loss function for the training\ndef loss_function(real, pred):\n  # create the mask to ignore the padding tokens\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  # mask shape == (batch_size, sequence_length)\n  # calculate the loss\n  loss_ = loss_object(real, pred)\n  # mask the loss\n  # how the mask works:\n  # if the value is 1, the loss is calculated\n  # if the value is 0, the loss is ignored\n    #[1,1,1,1,1,1,0,0,0,0,0] mask\n    # *\n    #[2,6,2,1,6,3,2,1,5,7,9] input\n    # =\n    #[2,6,2,1,6,3,0,0,0,0,0] output\n  mask = tf.cast(mask, dtype=loss_.dtype)\n  # mask shape == (batch_size, sequence_length)\n\n  loss_ *= mask\n  # calculate the average loss per batch \n  return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:47.300116Z","iopub.execute_input":"2023-07-23T19:55:47.301071Z","iopub.status.idle":"2023-07-23T19:55:47.312098Z","shell.execute_reply.started":"2023-07-23T19:55:47.301032Z","shell.execute_reply":"2023-07-23T19:55:47.311002Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# create the training metric \ntrain_loss = tf.metrics.Mean(name='train loss')\n# create the testing metric \ntest_loss =tf.metrics.Mean(name='test loss')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:48.277438Z","iopub.execute_input":"2023-07-23T19:55:48.277849Z","iopub.status.idle":"2023-07-23T19:55:48.293574Z","shell.execute_reply.started":"2023-07-23T19:55:48.277814Z","shell.execute_reply":"2023-07-23T19:55:48.292216Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# create the training step\n# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n@tf.function\n# define the training step \ndef train_step(inputs, target, enc_hidden):\n  # the encoder_hidden is the initial hidden state of the encoder\n  # enc_hidden shape == (batch_size, hidden_size)\n\n  # inilaize the loss to zero\n  loss = 0\n  # create the gradient tape to record the gradient of the loss with respect to the weights\n\n  with tf.GradientTape() as tape:\n    # pass the input to the encoder\n    # enc_output shape == (batch_size, 49, hidden_size)\n    # enc_hidden shape == (batch_size, hidden_size)\n    # using the encoder to get the encoder_output and the encoder_hidden\n    # using the encoder_hidden as the initial hidden state of the decoder\n    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n    # set the initial decoder hidden state to the encoder hidden state\n    dec_hidden = enc_hidden\n\n    # create the start token \n    # start_token shape == (batch_size, 1)\n    # repeat the start token for the batch size times\n    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n    \n    # Teacher forcing - feeding the target as the next input\n    \n    for t in range(1, target.shape[1]):\n      # passing enc_output to the decoder\n      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n      # calculate the loss for the current time step using the loss function\n      loss += loss_function(target[:, t], predictions)\n\n      # using teacher forcing\n      dec_input = tf.expand_dims(target[:, t], 1)\n  # calculate the loss for the current batch\n  batch_loss = (loss / int(target.shape[1]))\n\n  # get the trainable variables\n  variables = encoder.trainable_variables + decoder.trainable_variables\n  # calculate the gradients using the tape \n  gradients = tape.gradient(loss, variables)\n  # update the trainable variables\n  optimizer.apply_gradients(zip(gradients, variables))\n  # add the loss to the training loss metric\n  train_loss(batch_loss)\n  return batch_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:49.272583Z","iopub.execute_input":"2023-07-23T19:55:49.273012Z","iopub.status.idle":"2023-07-23T19:55:49.281649Z","shell.execute_reply.started":"2023-07-23T19:55:49.272978Z","shell.execute_reply":"2023-07-23T19:55:49.280784Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# create the training step\n# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n@tf.function \ndef test_step(inputs, target, enc_hidden):\n    # the encoder_hidden is the initial hidden state of the encoder\n    # enc_hidden shape == (batch_size, hidden_size)\n    # inilaize the loss to zero\n    loss = 0\n    # pass the input to the encoder \n    # enc_output shape == (batch_size, 49, hidden_size) \n    # enc_hidden shape == (batch_size, hidden_size)\n    # using the encoder to get the encoder_output and the encoder_hidden\n    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n    # set the initial decoder hidden state to the encoder hidden state\n    dec_hidden = enc_hidden\n    # create the start token\n    # start_token shape == (batch_size, 1)\n    # repeat the start token for the batch size times\n    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n    for t in range(1, target.shape[1]):\n        # passing enc_output to the decoder with dec_hidden as the initial hidden state\n        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n        # calculate the loss for the current time step using the loss function \n        loss += loss_function(target[:, t], predictions)\n\n        # using teacher forcing\n        dec_input = tf.expand_dims(target[:, t], 1)\n    # calculate the loss for the current batch\n    batch_loss = (loss / int(target.shape[1]))\n    # add the batch loss to the test loss metric\n    test_loss(batch_loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:50.290101Z","iopub.execute_input":"2023-07-23T19:55:50.290897Z","iopub.status.idle":"2023-07-23T19:55:50.298538Z","shell.execute_reply.started":"2023-07-23T19:55:50.290851Z","shell.execute_reply":"2023-07-23T19:55:50.297641Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# set the epochs to 10\nEPOCHS = 10\n# set the old test loss to high number \n\nold_test_loss=1000000\n# create the training loop\nfor epoch in range(EPOCHS):\n    # reset the training loss metric\n    train_loss.reset_states()\n    # reset the testing loss metric\n    test_loss.reset_states()\n\n    # initalize the hidden state of the encoder to zeros \n    enc_hidden = encoder.initialize_hidden_state()\n    # create the training progress bar set the total number of batches to the length of the training dataset and the batch size to the test size\n    steps_per_epoch = answer_sequence.shape[0]//batch_size #=> 4356 batch in the dataset \n    bar = tf.keras.utils.Progbar(target=steps_per_epoch)\n    \n    count=0\n    # iterate over the training dataset \n    for (batch, (inputs, target)) in enumerate(train_dataset):\n        # update the progress bar\n     count += 1\n        # run the training step\n     batch_loss = train_step(inputs, target, enc_hidden)\n     bar.update(count)  # manually update the progress bar\n                                                  \n    \n    \n    # iterate over the testing dataset    \n    for (batch, (inputs, target)) in enumerate(test_dataset):\n     count += 1\n        # run the testing step\n     batch_loss = test_step(inputs, target, enc_hidden)\n    bar.update(count)\n    # save the best performance model on the test dataset \n    \n    if old_test_loss> test_loss.result():\n        # set the old test loss to the test loss \n        old_test_loss= test_loss.result()\n        encoder.save(filepath='/content/models/encoder')\n        decoder.save(filepath='/content/models/decoder')\n        print('Model is saved')\n    # print the training and testing loss\n    print('#' * 50)\n    print(f'Epoch #{epoch + 1}')\n    print(f'Training Loss {train_loss.result()}')\n    print(f'Testing Loss {test_loss.result()}')\n    print('#' * 50)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T19:55:52.429328Z","iopub.execute_input":"2023-07-23T19:55:52.430261Z","iopub.status.idle":"2023-07-23T20:06:27.721633Z","shell.execute_reply.started":"2023-07-23T19:55:52.430220Z","shell.execute_reply":"2023-07-23T20:06:27.720442Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"  95/4356 [..............................] - ETA: 6:46:19","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# create the chatbot function\n# the chatbot function takes in the question as input and answers the input sentence \ndef chatbot(sentence):\n  \n  # clean the input question sentence \n  sentence = clean_text(sentence)\n  # add the start token to the sentence\n  sentence =add_start_end(sentence)\n  # tokenize the sentence\n  inputs = question_tokenizer.texts_to_sequences([sentence])\n  # pad the sentence\n  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                         maxlen=29,\n                                                         padding='post')\n  \n  # initalize the hidden state of the encoder to zeros\n  hidden = [tf.zeros((1, units))]\n  # pass the sentence to the encoder with the hidden state as the initial hidden state\n  enc_out, enc_hidden = encoder(inputs, hidden)\n  # set the initial decoder hidden state to the encoder hidden state\n  dec_hidden = enc_hidden\n  # create the start token\n  # start_token shape == (batch_size, 1)\n  # repeat the start token for the batch size times\n  dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']], 0)\n  # create the result string\n  result = ''\n  # loop over the length of the sentence (32)\n\n  for t in range(32):\n    # passing the encoder output and the decoder hidden state to the decoder make sure the decoder input is the previous predicted word\n    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n    # getting the predicted word index\n    predicted_id = tf.argmax(predictions[0]).numpy()\n    # getting the predicted word using the predicted index\n    # add the predicted word to the result string \n    result += answer_tokenizer.index_word[predicted_id] + ' '\n    # if the predicted word is the <end> token then stop the loop\n    if answer_tokenizer.index_word[predicted_id] == '<end>':\n      # remove the <start> and <end> tokens from the result string\n      result = result.replace('<start> ', '')\n      result = result.replace(' <end> ','')\n      # remove the <start> and <end> tokens from the sentence string\n      sentence = sentence.replace('<start> ', '')\n      sentence = sentence.replace(' <end>', '')\n      return  sentence, result\n\n    # using the predicted word as the next decoder input\n    dec_input = tf.expand_dims([predicted_id], 0)\n  # remove the <start> and <end> tokens from the result string\n  result = result.replace('<start> ', '')\n  result = result.replace('<end>','')\n  # remove the <start> and <end> tokens from the sentence string\n  sentence = sentence.replace('<start> ', '')\n  sentence = sentence.replace('<end>', '')\n  \n\n  \n \n  \n  # return the result string and the original sentence\n  return sentence, result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chatbot(\"how are you today\")","metadata":{"execution":{"iopub.status.busy":"2023-07-23T17:53:59.965858Z","iopub.execute_input":"2023-07-23T17:53:59.966303Z","iopub.status.idle":"2023-07-23T17:54:01.028337Z","shell.execute_reply.started":"2023-07-23T17:53:59.966267Z","shell.execute_reply":"2023-07-23T17:54:01.027196Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"('how are you today ',\n 'mom buckley skills anyth arkadin consummate afar panicky snoopy homecoming vee artistry antihistamine pedaling shutterbug rich stall cosgrove starter lockjaw enlisted puke drummers copied nicholai medals according updating airlock moishe spanked k ')"},"metadata":{}}]},{"cell_type":"code","source":"chatbot('what is the weather outside')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T17:54:08.618729Z","iopub.execute_input":"2023-07-23T17:54:08.619159Z","iopub.status.idle":"2023-07-23T17:54:09.630638Z","shell.execute_reply.started":"2023-07-23T17:54:08.619125Z","shell.execute_reply":"2023-07-23T17:54:09.629490Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"('what is the weather outside ',\n 'rene aversion advocacy pad citizens rats reds macre wilbur tattoos opr crawlin presented svengali drool bullmastiff fanelli hikers sweeping complimenting intermediates touch robertson matching readily didja vamanos smile youÂ¹re cowshit obituaries fisher ')"},"metadata":{}}]},{"cell_type":"code","source":"chatbot('can you run')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T17:54:15.967650Z","iopub.execute_input":"2023-07-23T17:54:15.968772Z","iopub.status.idle":"2023-07-23T17:54:16.970773Z","shell.execute_reply.started":"2023-07-23T17:54:15.968731Z","shell.execute_reply":"2023-07-23T17:54:16.969530Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"('can you run ',\n 'extravagant habra sais neutralize totals strawberry humpty ripple kinte ultrarelamensky trakyona francesca adams butner talking fi oy moldavia decoder licenses drawstring bearers swapped shooters camaro krikorian appliance postmarks marshal quickly energy mocking ')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}